%YAML 1.2
---
title: Add Scalar Double-Precision Floating-Point Values
validity: 32,64
opcode:
  - opcode: F2 0F 58 /r
    mnemonic: ADDSD \i{xmm1}, \i{xmm2/m64}
    encoding: LEGACY
    validity:
      32: valid
      64: valid
    cpuid: SSE2
    description: >-
      Adds a single double-precision floating-point value from \abbr{xmm2/m64} and \abbr{xmm1}.
      Stores the result in \abbr{xmm1}.
  - opcode: VEX.LIG.F2.0F.WIG 58 /r
    mnemonic: VADDSD \i{xmm1}, \i{xmm2}, \i{xmm3/m64}
    encoding: VEX
    validity:
      32: valid
      64: valid
    cpuid: AVX
    description: >-
      Adds a single double-precision floating-point value from \abbr{xmm3/m64} and \abbr{xmm2}.
      Stores the result in \abbr{xmm1}.
  - opcode: EVEX.LIG.F2.0F.W1 58 /r
    mnemonic: VADDSD \i{xmm1} {k1}{z}, \i{xmm2}, \i{xmm3/m64} {er}
    encoding: EVEX
    validity:
      32: valid
      64: valid
    cpuid: AVX512F
    description: >-
      Adds a single double-precision floating-point value from \abbr{xmm3/m64} and \abbr{xmm2}.
      Stores the result in \abbr{xmm1} using writemask \abbr{k1}.
encoding:
  operands: 3
  hasTuple: true
  encodings:
    LEGACY:
      - N/A
      - ModRM.reg[rw]
      - ModRM.r/m[r]
      - ""
    VEX:
      - N/A
      - ModRM.reg[w]
      - VEX.vvvv[r]
      - ModRM.r/m[r]
    EVEX:
      - Tuple1 Scalar
      - ModRM.reg[w]
      - EVEX.vvvv[r]
      - ModRM.r/m[r]
description: >-
  The \c{(V)ADDSD} instruction adds a single double-precision floating-point from the first source operand and the second source operand and stores the result in the destination operand.

  The legacy SSE version (\c{ADDSD}) works on the lowest 64 bits and leaves all others unchanged.

  The AVX versions (\c{VADDSD}) work on the lowest 64 bits, but also copy the next 64 bits from the first source operand to the destination.
  Afterwards, all unchanged bits in the destination are zeroed.

  Although this instruction works with \c{(E)VEX.LIG}, Intel recommends that assemblers set \c{(E)VEX.L} to 0.
  Encoding with \c{(E)VEX.L} being 1 may not be allowed in the future.
operation: |-
  pub fn addsd(dest: &mut Simd<f64>, src: Simd<f64>) {
    dest[63..=0] = dest[63..=0] + src[63..=0];
    // dest[Simd::max()..=64] (unmodified)
  }

  pub fn vaddsd_vex(dest: &mut Simd<f64>, src1: Simd<f64>, src2: Simd<f64>) {
    dest[63..=0] = src1[63..=0] + src2[63..=0];
    dest[127..=64] = src1[127..=64];
    dest[Simd::max()..=128] = 0;
  }

  pub fn vaddsd_evex(dest: &mut Simd<f64>, src1: Simd<f64>, src2: Simd<f64>, k: KMask) {
    set_rounding_for_this_instruction(if EVEX.b && src2.is_reg() { EVEX.RC } else { MXCSR.RC });

    if k[0] {
      dest[63..=0] = src1[63..=0] + src2[63..=0];
    } else {
      // zero mask?
      if EVEX.z {
        dest[63..=0] = 0;
      }
    }

    dest[127..=64] = src1[127..=64];
    dest[Simd::max()..=128] = 0;
  }
intrinsicsC: |-
  __m128d _mm_add_sd(__m128d a, __m128d b)
  __m128d _mm_add_round_sd(__m128d a, __m128d b, int32_t rounding)
  __m128d _mm_mask_add_sd(__m128d s, __mmask8 k, __m128d a, __m128d b)
  __m128d _mm_mask_add_round_sd(__m128d s, __mmask8 k, __m128d a, __m128d b, int32_t rounding)
  __m128d _mm_maskz_add_sd(__mmask8 k, __m128d a, __m128d b)
  __m128d _mm_maskz_add_round_sd (__mmask8 k, __m128d a, __m128d b, int32_t rounding)
exceptions:
  floating: Overflow, Underflow, Invalid, Precision, Denormal
  other:
    - "VEX encoded form: see Exceptions Type 2."
    - "EVEX encoded form: see Exceptions Type E2."
